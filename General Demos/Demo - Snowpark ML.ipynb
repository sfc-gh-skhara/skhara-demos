{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d72538",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb04fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, StringType,StructType, StructField, DecimalType\n",
    "\n",
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.registry import registry\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snowflake-ml-python --index-url https://repo.anaconda.com/pkgs/snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dir = os.getcwd()\n",
    "# connection_parameters = json.load(open(f'{my_dir}/creds.json'))\n",
    "connection_parameters = json.load(open('/Users/skhara/Documents/Code/creds.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67790ddf",
   "metadata": {},
   "source": [
    "# <font color='red'>Snowpark with Big Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_warehouse('ML_WORKLOADS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_df = session.table('CITIBIKEML_JACK.DEMO.TRIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "snow_df.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a522874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Size of the Snowpark DF: ', snow_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the last query ID directly using Snowpark's session object\n",
    "# This uses the LAST_QUERY_ID() function which gives the ID of the last query executed in the session\n",
    "last_query_id = session.sql(\"SELECT LAST_QUERY_ID()\").collect()[0][0]\n",
    "print(f\"The last query ID is: {last_query_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pandas_df = snow_df.with_column(\"date\", F.to_date(\"STARTTIME\")).group_by(\"date\").count().sort(\"date\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.lineplot(x='DATE', y='COUNT', data=pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb5f2e-7dd3-4a2e-af77-14bbcde7202f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b38abe0",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "# \n",
    " \n",
    "# <font color='red'>Snowpark for ML</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efba6a2",
   "metadata": {},
   "source": [
    "## 1.0 Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f148313",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('ALTER WAREHOUSE SSK_RESEARCH SET WAREHOUSE_SIZE = \"LARGE\"').collect()\n",
    "session.use_warehouse('SSK_RESEARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a019f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_database('DEMO_DB')\n",
    "session.use_schema('PUBLIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Snowpark DataFrame\n",
    "application_record_sdf = session.table('APPLICATION_RECORD')\n",
    "credit_record_sdf = session.table('CREDIT_RECORD')\n",
    "print('Application table size\\t: ',application_record_sdf.count(), \n",
    "      '\\nCredit table size\\t: ', credit_record_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_record_sdf.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a new column, TARGET, that will have a 1 for high-risk and 0 for low-risk.\n",
    "credit_record_sdf = credit_record_sdf.group_by('ID')\\\n",
    "                        .agg(F.sum(F.iff(F.col('STATUS').in_(['2', '3','4','5']), 1, 0)).as_(\"CNT_LATE\"))\\\n",
    "                        .with_column('TARGET', F.when(F.col('CNT_LATE') > 0, 1).otherwise(0)).drop(\"CNT_LATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Credit Record data with Application Record Data\n",
    "joined_sdf = application_record_sdf.join(credit_record_sdf, using_columns='ID', join_type='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Removal - Use the **drop_duplicates** to remove duplicated rows\n",
    "joined_sdf = joined_sdf.drop_duplicates('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a few columns for modeling\n",
    "cols_numerical = ['AMT_INCOME_TOTAL', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'CNT_FAM_MEMBERS']\n",
    "cols_categorical = ['CODE_GENDER', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "target = ['TARGET']\n",
    "joined_sdf = joined_sdf[cols_numerical + cols_categorical + target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de497de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sdf.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "            (\n",
    "                \"OHE\",\n",
    "                snowml.OneHotEncoder(\n",
    "                    input_cols=cols_categorical,\n",
    "                    output_cols=cols_categorical,\n",
    "                    drop_input_cols=True\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                \"XGBModel\",\n",
    "                XGBClassifier(\n",
    "                    random_state=123,\n",
    "                    input_cols=feature_cols,\n",
    "                    label_cols=target_col,\n",
    "                    output_cols='PREDICTION',\n",
    "                )\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformed_df = preprocessing_pipeline.fit(joined_sdf).transform(joined_sdf)\n",
    "transformed_df.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb954edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning column names to make it easier for future referencing\n",
    "import re\n",
    "\n",
    "cols = transformed_df.columns\n",
    "for old_col in cols:\n",
    "    new_col = re.sub(r'[^a-zA-Z0-9_]', '', old_col)\n",
    "    new_col = new_col.upper()\n",
    "    transformed_df = transformed_df.rename(col(old_col), new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data and save the train and test sets as tables in Snowflake\n",
    "snowdf_train, snowdf_test = transformed_df.random_split([0.8, 0.2], seed=82) \n",
    "snowdf_train.write.mode(\"overwrite\").save_as_table(\"CREDIT_DEFAULT_TRAIN\")\n",
    "snowdf_test.write.mode(\"overwrite\").save_as_table(\"CREDIT_DEFAULT_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d093ad",
   "metadata": {},
   "source": [
    "## 2.0 ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('ALTER WAREHOUSE SSK_RESEARCH SET WAREHOUSE_SIZE = \"LARGE\"').collect()\n",
    "session.use_warehouse('SSK_RESEARCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data for modeling\n",
    "snowdf_train = session.table('DEMO_DB.PUBLIC.CREDIT_DEFAULT_TRAIN')\n",
    "feature_cols = snowdf_train.columns\n",
    "target_col = 'TARGET'\n",
    "feature_cols.remove(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBClassifier and fit the model\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "xgbmodel = XGBClassifier(random_state=123, input_cols=feature_cols, label_cols=target_col, output_cols='PREDICTION')\n",
    "xgbmodel.fit(snowdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb8667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score the data using the fitted xgbmodel\n",
    "snowdf_test = session.table('CREDIT_DEFAULT_TEST')\n",
    "scored_sdf = xgbmodel.predict(snowdf_test)\n",
    "print(snowdf_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a313f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Metrics\n",
    "from snowflake.ml.modeling.metrics import f1_score, accuracy_score\n",
    "F1 = f1_score(df = scored_sdf,\n",
    "              y_true_col_names = 'TARGET',\n",
    "              y_pred_col_names = 'PREDICTION')\n",
    "ACCURACY = accuracy_score(df = scored_sdf,\n",
    "                          y_true_col_names = 'TARGET',\n",
    "                          y_pred_col_names = 'PREDICTION')\n",
    "print(f'F1 Score: {F1} \\nAccuracy Score: {ACCURACY}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2f5c3",
   "metadata": {},
   "source": [
    "### Now, let's use Snowpark ML's Distributed GridSearchCV() function to find optimal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f952c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(),\n",
    "    param_grid={\n",
    "        \"n_estimators\":[100, 200],\n",
    "        \"learning_rate\":[0.3],\n",
    "        \"max_depth\": [1,3]\n",
    "    },\n",
    "    n_jobs = 1,\n",
    "    scoring=\"neg_mean_absolute_percentage_error\",\n",
    "    input_cols=feature_cols,\n",
    "    label_cols=target_col,\n",
    "    output_cols='PREDICTION'\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search.fit(snowdf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'DEMO_DB'\n",
    "schema = 'CREDIT_APPROVAL'\n",
    "\n",
    "# Create a registry and log the model\n",
    "native_registry = registry.Registry(session=session, database_name=db, schema_name=schema)\n",
    "native_registry.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3752caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model name\n",
    "model_name = \"TEST_DELETE_LATER\"\n",
    "model_version = f\"V1_{pd.datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "# Let's log the best model trained\n",
    "model_ver = native_registry.log_model(\n",
    "    model_name= model_name,\n",
    "    version_name= model_version,\n",
    "    model= xgbmodel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6409108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TEST_DELETE_LATER\"\n",
    "model_version = f\"V1_{pd.datetime.now().strftime('%Y_%m_%d')}\"\n",
    "\n",
    "native_registry.get_model(model_name).show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowdf_test = session.table('CREDIT_DEFAULT_TEST')\n",
    "model_name = \"DEMO_CREDIT_XGB\"\n",
    "model_version = 'V0'\n",
    "\n",
    "model_ver = native_registry.get_model(model_name).version(model_version)\n",
    "model_ver.show_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adacd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowdf_test = session.table('CREDIT_DEFAULT_TEST')\n",
    "model_name = \"TEST_DELETE_LATER\"\n",
    "model_version = 'V0'\n",
    "\n",
    "model_ver = native_registry.get_model(model_name).default\n",
    "result_sdf2 = model_ver.run(snowdf_train, function_name=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97730140",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sdf2.write.mode(\"overwrite\").save_as_table(\"RESULTS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ff2fb-c33c-48d9-a1eb-49bca2d9127f",
   "metadata": {},
   "source": [
    "# Want to Deploy and Schedule Your Code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90e4cd-bd9a-435a-8d95-59ad965d2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.core import Root\n",
    "from snowflake.core.task import StoredProcedureCall, Task\n",
    "from snowflake.core.task.dagv1 import DAGOperation, DAG, DAGTask\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_root = Root(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_step1(session:Session):\n",
    "    session.use_database('DEMO_DB')\n",
    "    session.use_schema('PUBLIC')\n",
    "        # Creating a Snowpark DataFrame\n",
    "    application_record_sdf = session.table('APPLICATION_RECORD')\n",
    "    credit_record_sdf = session.table('CREDIT_RECORD')\n",
    "\n",
    "    # We will create a new column, TARGET, that will have a 1 for high-risk and 0 for low-risk.\n",
    "    credit_record_sdf = credit_record_sdf.group_by('ID')\\\n",
    "                            .agg(F.sum(F.iff(F.col('STATUS').in_(['2', '3','4','5']), 1, 0)).as_(\"CNT_LATE\"))\\\n",
    "                            .with_column('TARGET', F.when(F.col('CNT_LATE') > 0, 1).otherwise(0)).drop(\"CNT_LATE\")\n",
    "\n",
    "    \n",
    "    # Join Credit Record data with Application Record Data\n",
    "    joined_sdf = application_record_sdf.join(credit_record_sdf, using_columns='ID', join_type='inner')\n",
    "    # Duplicate Removal - Use the **drop_duplicates** to remove duplicated rows\n",
    "    joined_sdf = joined_sdf.drop_duplicates('ID')\n",
    "\n",
    "    # Selecting a few columns for modeling\n",
    "    cols_numerical = ['AMT_INCOME_TOTAL', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'CNT_FAM_MEMBERS', 'TARGET']\n",
    "    cols_categorical = ['CODE_GENDER', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "    joined_sdf = joined_sdf[cols_numerical+cols_categorical]\n",
    "    return joined_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d338d-a658-4e50-90ed-f08c7bddea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_data_preprocess_pipeline(session:Session) -> str:\n",
    "    import snowflake.snowpark.functions as F\n",
    "    from snowflake.snowpark.functions import udf\n",
    "    from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "    import re\n",
    "\n",
    "    joined_sdf = func_step1(Session)\n",
    "    # Perform One-Hot-Encoding for categorical columns\n",
    "    my_ohe_encoder = OneHotEncoder(input_cols=cols_categorical, output_cols=cols_categorical, drop_input_cols=True)\n",
    "    prepared_sdf = my_ohe_encoder.fit(joined_sdf).transform(joined_sdf)\n",
    "\n",
    "    cols = prepared_sdf.columns\n",
    "    for old_col in cols:\n",
    "        new_col = re.sub(r'[^a-zA-Z0-9_]', '', old_col)\n",
    "        new_col = new_col.upper()\n",
    "        prepared_sdf = prepared_sdf.rename(col(old_col), new_col)\n",
    "\n",
    "    # Save the data as table in Snowflake\n",
    "    prepared_sdf.write.mode(\"overwrite\").save_as_table(\"PIPE_CREDIT_DEFAULT\")\n",
    "    \n",
    "    return f\"Preprocessing pipeline ran successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_inference_pipeline(session:Session) -> str:\n",
    "    from snowflake.ml.registry import registry\n",
    "    registry = registry.Registry(session=session, database_name=db, schema_name=schema)\n",
    "    \n",
    "    # Get data\n",
    "    snowdf_test = session.table('PIPE_CREDIT_DEFAULT')\n",
    "    model_name = \"DEMO_CREDIT_XGB\"\n",
    "    model_ver = registry.get_model(model_name).default\n",
    "    result_sdf = model_ver.run(snowdf_test, function_name=\"predict\")\n",
    "    result_sdf.write.mode(\"overwrite\").save_as_table(\"SCORED_CREDIT_DEFAULT\")\n",
    "    return f\"Inference pipeline ran successfully\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7132ce-f3a8-418a-9b95-3ae341332a5b",
   "metadata": {},
   "source": [
    "#### Setup Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa691a11-dec8-44af-976b-959fb75d84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = api_root.databases['DEMO_DB'].schemas['PUBLIC']\n",
    "tasks = schema.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f2469-0ae3-472c-a749-637402523a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 stuff\n",
    "task1_entity = Task(\n",
    "    \"preprocess_pipeline\",\n",
    "    definition=StoredProcedureCall(func_data_preprocess_pipeline, stage_location=\"@ML_MODELS\", packages=[\"snowflake-snowpark-python\",\"snowflake-ml-python\", \"regex\"]),\n",
    "    warehouse='SSK_RESEARCH',\n",
    "    schedule=timedelta(days=1))\n",
    "\n",
    "task1 = tasks.create(task1_entity, mode=\"orReplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 stuff\n",
    "task2_entity = Task(\n",
    "    \"inference_pipeline\",\n",
    "    definition=StoredProcedureCall(func_inference_pipeline, stage_location=\"@ML_MODELS\", packages=[\"snowflake-snowpark-python\"]),\n",
    "    warehouse='SSK_RESEARCH')\n",
    "\n",
    "task2_entity.predecessors = [\"DEMO_DB.PUBLIC.PREPROCESS_PIPELINE\"]\n",
    "task2 = tasks.create(task2_entity, mode=\"orReplace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43211626-1965-4e25-93b7-40694a9dac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2.resume()\n",
    "task1.resume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f769b8-d87b-4b7a-aef4-0c13bc319fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d559caf-6e94-47e7-a0a2-e2ecafaed18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd562b-4e56-4d8b-9156-5b2c3651ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
