{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea36370",
   "metadata": {},
   "source": [
    "# Steps in this Notebook\n",
    "\n",
    "1. Imports\n",
    "2. Snowflake Setup\n",
    "3. Local testing wit MLForecast\n",
    "4. Snowflake testing with MLForecast using UDTF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d72538",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb04fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, StringType,StructType, StructField\n",
    "\n",
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.modeling.preprocessing import KBinsDiscretizer, OrdinalEncoder, OneHotEncoder\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = json.load(open('/Users/skhara/Documents/Code/creds.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697a78d-dfe2-4b7d-92a0-ae48c7053b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf6745",
   "metadata": {},
   "source": [
    "# Snowflake Setup: Create a Database and Schema\n",
    "\n",
    "We will be using PUBLIC schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TS data from Store_Traffic Database into ACCRUENT_TS_FORECASTING DB for testing purposes.\n",
    "sdf_raw = session.table('TIME_SERIES_1K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ff284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Number of Time Series/Pumps that we have to predict\n",
    "session.sql('SELECT COUNT(DISTINCT SERIES_ID) FROM TIME_SERIES_1K').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5e478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the SERIES_ID and Start and End date of Time Series\n",
    "session.sql('SELECT SERIES_ID, MIN(DATE), MAX(DATE) FROM TIME_SERIES_1K GROUP BY SERIES_ID').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_raw.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_raw.describe().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caa133",
   "metadata": {},
   "source": [
    "# Local Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd657a-7f5e-4ee9-b766-b1238876a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = sdf_raw.filter((F.col(\"SERIES_ID\") == 62)).to_pandas()\n",
    "\n",
    "# Here onwards copy paste in UDTF\n",
    "df_data['DATE'] = pd.to_datetime(df_data['DATE'])\n",
    "df_data.groupby('DATE').sum('VALUE').reset_index()\n",
    "# df_data = df_data[['DATE','VALUE']]\n",
    "df_data = df_data.sort_values(by=['DATE']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f853f-b8ba-4112-87c2-77d71517a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84792e4-0075-4c5d-9cb0-e2d22f8f635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.set_index('DATE')['VALUE'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb70ed-8a82-4297-b70a-a2bcd480e38d",
   "metadata": {},
   "source": [
    "### Testing with Nixtla MLForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ae7c3-4bfe-4803-8470-8d19fe7c8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlf = df_data.copy()\n",
    "df_mlf.columns = ['ds', 'unique_id', 'y']\n",
    "df_mlf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45cc91-93ea-43d7-a80b-e8fe4eb23877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import Differences\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc40b6-f0e0-4466-9307-55d383d241a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b4c76-8573-457f-98eb-06ec152dc948",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = MLForecast(\n",
    "    models=[LinearRegression(),XGBRegressor()],\n",
    "    freq='D',  # our serie has a monthly frequency\n",
    "    lags=[1,7,28,60],\n",
    "    target_transforms=[Differences([1])],\n",
    ")\n",
    "fcst.fit(df_mlf.iloc[0:-fh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c98f5-61dd-4d3b-a6da-5fcd8e8c1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(fh)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a208a-d3be-4479-9d17-d9a9a317342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = preds.merge(df_mlf, left_on=['ds','unique_id'], right_on = ['ds','unique_id'],how='left')\n",
    "df_res = df_res.drop('unique_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b1e9c0-a0ba-4107-ae9e-f542238b0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_res.copy()\n",
    "df.set_index('ds', inplace=True)\n",
    "\n",
    "# Plotting the time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(df.index, df['LinearRegression'], label='Linear Regression')\n",
    "plt.plot(df.index, df['XGBRegressor'], label='XGB Regressor')\n",
    "plt.plot(df.index, df['y'], label='Actual Values')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Time Series Plot')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7dd1c",
   "metadata": {},
   "source": [
    "# Creating UDTF for multi-node parallelized model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdd949-b55b-41de-a25e-6405bea7a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"ID\", T.IntegerType()),\n",
    "    T.StructField(\"TIMESTAMP\", T.DateType()),\n",
    "    T.StructField(\"LINREG\", T.FloatType()),\n",
    "    T.StructField(\"XGB\", T.FloatType()),\n",
    "    T.StructField(\"TRAIN_START\", T.DateType()),\n",
    "    T.StructField(\"TRAIN_END\", T.DateType()),\n",
    "    T.StructField(\"FORECAST_HORIZON\", T.IntegerType())\n",
    "                  ])\n",
    "\n",
    "@F.udtf(output_schema = schema,\n",
    "        input_types = [T.VariantType()],\n",
    "        name = \"TSF_MLFORECAST\", is_permanent=True, stage_location= \"@DEMO_DB.PUBLIC.ML_MODELS\", session=session,\n",
    "        packages=['pandas', 'mlforecast' ,'xgboost', 'scikit-learn'],\n",
    "        replace=True\n",
    "       )\n",
    "\n",
    "class forecast:\n",
    "    def __init__(self):\n",
    "        self.rows=[]\n",
    "        self.dfs=[]\n",
    "    \n",
    "    def process(self, data):\n",
    "        self.rows.append(data)\n",
    "\n",
    "        # Merge rows into a dataframe\n",
    "        if len(self.rows) >= 16000:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "        \n",
    "        # Merge dataframes into a single dataframe\n",
    "        # Minimizes memory footprint\n",
    "        if len(self.dfs) >= 100:\n",
    "            merged_df = pd.concat(self.dfs)\n",
    "            self.dfs = [merged_df]\n",
    "\n",
    "        yield None\n",
    "    \n",
    "    def end_partition(self):\n",
    "        # Merge any remaining rows\n",
    "        from mlforecast import MLForecast\n",
    "        from mlforecast.target_transforms import Differences\n",
    "        from xgboost import XGBRegressor\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "\n",
    "        if len(self.rows) > 0:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "\n",
    "        # Process Input\n",
    "        df_input = pd.concat(self.dfs)\n",
    "        df_input['DATE'] = pd.to_datetime(df_input['DATE'])\n",
    "        df_input.groupby(['DATE','SERIES_ID']).sum('VALUE').reset_index()\n",
    "        df_input = df_input[['DATE','SERIES_ID','VALUE']]\n",
    "        df_input.columns = ['ds','unique_id','y']\n",
    "\n",
    "        #Train + Forecast Length\n",
    "        train_length = 600\n",
    "        fh = 30 # Forecast Horizon\n",
    "        train_end = max(df_input['ds'])\n",
    "        train_start = train_end - pd.Timedelta(days = 600)\n",
    "        \n",
    "        df_input = df_input.loc[(df_input['ds'] >= train_start) &\n",
    "                                (df_input['ds'] < train_end)].reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        fcst = MLForecast(models=[LinearRegression(),XGBRegressor()],\n",
    "                          freq='D',\n",
    "                          lags=[1,7,28,60],\n",
    "                          target_transforms=[Differences([1])])\n",
    "        \n",
    "        fcst.fit(df_mlf.iloc[0:-fh])\n",
    "\n",
    "        ts_forecast = fcst.predict(fh)\n",
    "        \n",
    "        # Processing\n",
    "        ts_forecast.columns = ['ID','TIMESTAMP','LINREG','XGB']\n",
    "        ts_forecast['TRAIN_START'] = train_start\n",
    "        ts_forecast['TRAIN_END'] = train_end\n",
    "        ts_forecast['FORECAST_HORIZON'] = fh\n",
    "\n",
    "        yield from ts_forecast.itertuples(index=False, name=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e564cf-8057-4e90-af0e-2a71574a515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_raw.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ceb61-a055-4c6a-805a-b795fbd90f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = session.table('TIME_SERIES') \\\n",
    "        .with_column('ROW', F.object_construct_keep_null('*')) \\\n",
    "        .select(F.col('SERIES_ID'), F.col('ROW'))\n",
    "\n",
    "store_forecast_test = F.table_function(\"TSF_MLFORECAST\")\n",
    "\n",
    "variant_column = F.parse_json(df.col('ROW').cast(T.VariantType()))\n",
    "\n",
    "forecast = df.select(\n",
    "                F.col('SERIES_ID'), \n",
    "                store_forecast_test(variant_column).over(partition_by=['SERIES_ID'])\n",
    "                )\n",
    "\n",
    "forecast = forecast.with_column('FORECAST_DATETIME', F.current_timestamp())\n",
    "forecast.write.save_as_table(\"DEMO_DB.PUBLIC.FORECAST_USING_MLFORECAST\", mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e0f1f-202b-4bfd-9f40-c4d9b58ccb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_ref = session.table('DEMO_DB.PUBLIC.FORECAST_USING_MLFORECAST')\n",
    "sdf_ref.limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17284b91-e68d-4520-9cba-ec37aa4a5531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63369f08-f95d-4139-8c6d-1a250b381b40",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "Two options -\n",
    "1. Create a task using SQL\n",
    "2. Create a task using Task API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031f764-d987-4324-aedf-5a6bfe4fe2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8d1d6-6db4-4f63-a252-63d73157f356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
