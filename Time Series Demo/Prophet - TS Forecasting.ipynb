{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea36370",
   "metadata": {},
   "source": [
    "# Steps in this Notebook\n",
    "\n",
    "1. Imports\n",
    "2. Snowflake Setup\n",
    "3. Local Prophet model Test\n",
    "4. UDTF Prophet for Parallel Compute\n",
    "5. Prophet==1.1.5 Test (not working atm. Snowflake team on it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d72538",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cb04fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, StringType,StructType, StructField\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cc080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = json.load(open('/Users/skhara/Documents/Code/creds.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0697a78d-dfe2-4b7d-92a0-ae48c7053b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/skhara/Documents/Code/Customer Code/2024-01 - Prophet==1.1.5 Test'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf6745",
   "metadata": {},
   "source": [
    "# Snowflake Setup: Create a Database and Schema\n",
    "\n",
    "We will be using PUBLIC schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0866765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('USE DATABASE TIME_SERIES').collect()\n",
    "session.sql('USE SCHEMA SYNTHETIC_DATA').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463a699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TS data from Store_Traffic Database into ACCRUENT_TS_FORECASTING DB for testing purposes.\n",
    "sdf_raw = session.table('TIME_SERIES_1K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6ff284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(COUNT(DISTINCT SERIES_ID)=1000)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the Number of Time Series/Pumps that we have to predict\n",
    "session.sql('SELECT COUNT(DISTINCT SERIES_ID) FROM TIME_SERIES_1K').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdff238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SUMMARY='count', SERIES_ID=2046000.0, VALUE=2046000.0),\n",
       " Row(SUMMARY='mean', SERIES_ID=500.5, VALUE=124.109512),\n",
       " Row(SUMMARY='stddev', SERIES_ID=288.67506080366553, VALUE=35.57537708865502),\n",
       " Row(SUMMARY='min', SERIES_ID=1.0, VALUE=44.0),\n",
       " Row(SUMMARY='max', SERIES_ID=1000.0, VALUE=246.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_raw.describe().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caa133",
   "metadata": {},
   "source": [
    "# Local Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41cd657a-7f5e-4ee9-b766-b1238876a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n",
      "12:35:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:35:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>FORECAST</th>\n",
       "      <th>TRAIN_START</th>\n",
       "      <th>TRAIN_END</th>\n",
       "      <th>FORECAST_HORIZON</th>\n",
       "      <th>LIBRARY_VERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>149.580651</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>136.509438</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>141.670957</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>159.879076</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>177.866228</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>159.915620</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>178.099985</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>196.063384</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>200.465051</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>187.933910</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TIMESTAMP    FORECAST TRAIN_START  TRAIN_END  FORECAST_HORIZON  \\\n",
       "0   2021-12-17  149.580651  2021-12-16 2023-08-08                30   \n",
       "1   2021-12-18  136.509438  2021-12-16 2023-08-08                30   \n",
       "2   2021-12-19  141.670957  2021-12-16 2023-08-08                30   \n",
       "3   2021-12-20  159.879076  2021-12-16 2023-08-08                30   \n",
       "4   2021-12-21  177.866228  2021-12-16 2023-08-08                30   \n",
       "..         ...         ...         ...        ...               ...   \n",
       "625 2023-09-03  159.915620  2021-12-16 2023-08-08                30   \n",
       "626 2023-09-04  178.099985  2021-12-16 2023-08-08                30   \n",
       "627 2023-09-05  196.063384  2021-12-16 2023-08-08                30   \n",
       "628 2023-09-06  200.465051  2021-12-16 2023-08-08                30   \n",
       "629 2023-09-07  187.933910  2021-12-16 2023-08-08                30   \n",
       "\n",
       "    LIBRARY_VERSION  \n",
       "0             1.1.5  \n",
       "1             1.1.5  \n",
       "2             1.1.5  \n",
       "3             1.1.5  \n",
       "4             1.1.5  \n",
       "..              ...  \n",
       "625           1.1.5  \n",
       "626           1.1.5  \n",
       "627           1.1.5  \n",
       "628           1.1.5  \n",
       "629           1.1.5  \n",
       "\n",
       "[630 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = sdf_raw.filter((F.col(\"SERIES_ID\") == 62)).to_pandas()\n",
    "\n",
    "# Here onwards copy paste in UDTF\n",
    "import prophet\n",
    "\n",
    "df_data['ds'] = pd.to_datetime(df_data['DATE'])\n",
    "df_data = df_data.groupby('ds').sum('VALUE').reset_index()\n",
    "df_data = df_data.rename(columns={'VALUE':'y'})\n",
    "df_data = df_data[['ds','y']]\n",
    "df_data = df_data.sort_values(by=['ds']).reset_index(drop=True)\n",
    "\n",
    "# Set train start\n",
    "train_length = 600\n",
    "forecast_horizon = 30\n",
    "train_end = max(df_data['ds'])\n",
    "train_start = train_end - pd.Timedelta(days = 600)\n",
    "\n",
    "# Get training data\n",
    "df_data = df_data.loc[(df_data['ds'] > train_start) & (df_data['ds'] <= train_end)]\n",
    "\n",
    "# Model fit and predict\n",
    "model = prophet.Prophet()\n",
    "model.fit(df_data)\n",
    "future = model.make_future_dataframe(periods=30)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Post process forecast\n",
    "forecast = forecast[['ds','yhat']]\n",
    "forecast.columns = ['TIMESTAMP','FORECAST']\n",
    "forecast['TRAIN_START'] = train_start\n",
    "forecast['TRAIN_END'] = train_end\n",
    "forecast['FORECAST_HORIZON'] = forecast_horizon\n",
    "forecast['LIBRARY_VERSION'] = str(prophet.__version__)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "226f5f2a-fa0b-41ca-a969-a0d7e7587f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.plot(forecast)\n",
    "# model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7dd1c",
   "metadata": {},
   "source": [
    "# Creating UDTF for multi-node parallelized model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4c8c7c1-0a77-465a-bb19-5f9a2125790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='TEST_PROPHET_115 already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('USE DATABASE TIME_SERIES').collect()\n",
    "session.sql('USE SCHEMA SYNTHETIC_DATA').collect()\n",
    "session.sql('USE WAREHOUSE ML_WORKLOADS').collect()\n",
    "session.sql('CREATE STAGE IF NOT EXISTS TEST_PROPHET_115').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7703887",
   "metadata": {},
   "source": [
    "## Snow Conda Prophet==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6b5aace-ad30-49be-a877-f50caf0f76ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'prophet' in the local environment is 1.1.5, which does not fit the criteria for the requirement 'prophet'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"TIMESTAMP\", T.DateType()),\n",
    "    T.StructField(\"FORECAST\", T.FloatType()),\n",
    "    T.StructField(\"TRAIN_START\", T.DateType()),\n",
    "    T.StructField(\"TRAIN_END\", T.DateType()),\n",
    "    T.StructField(\"FORECAST_HORIZON\", T.IntegerType()),\n",
    "    T.StructField(\"LIBRARY_VERSION\", T.StringType())\n",
    "])\n",
    "\n",
    "@F.udtf(session=session,\n",
    "        output_schema = schema,\n",
    "        input_types = [T.VariantType()],\n",
    "        name = \"TESTING_PROPHET_101\",\n",
    "        is_permanent=True,\n",
    "        stage_location=\"@TIME_SERIES.SYNTHETIC_DATA.TEST_PROPHET_115\",\n",
    "        packages=['pandas==1.5.3','prophet', 'holidays==0.18', 'snowflake-snowpark-python','tqdm'],\n",
    "        replace=True\n",
    "       )\n",
    "\n",
    "class forecast:\n",
    "    def __init__(self):\n",
    "        self.rows=[]\n",
    "        self.dfs=[]\n",
    "    \n",
    "    def process(self, data):\n",
    "        self.rows.append(data)\n",
    "        # Merge rows into a dataframe\n",
    "        if len(self.rows) >= 16000:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "        # Merge dataframes into a single dataframe. Minimizes memory footprint\n",
    "        if len(self.dfs) >= 100:\n",
    "            merged_df = pd.concat(self.dfs)\n",
    "            self.dfs = [merged_df]\n",
    "        yield None\n",
    "    \n",
    "    def end_partition(self):\n",
    "        from prophet import Prophet\n",
    "        import prophet\n",
    "\n",
    "        if len(self.rows) > 0:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "\n",
    "        # Preprocess Data\n",
    "        df_data = pd.concat(self.dfs)\n",
    "        df_data['ds'] = pd.to_datetime(df_data['DATE'])\n",
    "        df_data = df_data.groupby('ds').sum('VALUE').reset_index()\n",
    "        df_data = df_data.rename(columns={'VALUE':'y'})\n",
    "        df_data = df_data[['ds','y']]\n",
    "        df_data = df_data.sort_values(by=['ds']).reset_index(drop=True)\n",
    "\n",
    "        # Set train start\n",
    "        train_length = 600\n",
    "        forecast_horizon = 30\n",
    "        train_end = max(df_data['ds'])\n",
    "        train_start = train_end - pd.Timedelta(days = 600)\n",
    "\n",
    "        # Get training data\n",
    "        df_data = df_data.loc[(df_data['ds'] > train_start) & (df_data['ds'] <= train_end)]\n",
    "\n",
    "        # Model fit and predict\n",
    "        model = Prophet()\n",
    "        model.fit(df_data)\n",
    "        future = model.make_future_dataframe(periods=forecast_horizon)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Post process forecast\n",
    "        forecast = forecast[['ds','yhat']]\n",
    "        \n",
    "        forecast.columns = ['TIMESTAMP','FORECAST']\n",
    "        forecast['TRAIN_START'] = train_start\n",
    "        forecast['TRAIN_END'] = train_end\n",
    "        forecast['FORECAST_HORIZON'] = forecast_horizon\n",
    "        forecast['LIBRARY_VERSION'] = str(prophet.__version__)\n",
    "\n",
    "        yield from forecast.itertuples(index=False, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a11324af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = session.table('TIME_SERIES_1K') \\\n",
    "        .with_column('ROW', F.object_construct_keep_null('*')) \\\n",
    "        .select(F.col('SERIES_ID'), F.col('ROW')) \\\n",
    "        .filter(F.col('SERIES_ID').isin([1,2,3,4,5]))\n",
    "\n",
    "store_forecast_test = F.table_function(\"TESTING_PROPHET_101\")\n",
    "\n",
    "variant_column = F.parse_json(df.col('ROW').cast(T.VariantType()))\n",
    "\n",
    "forecast_sdf = df.select(F.col('SERIES_ID'),\n",
    "                         store_forecast_test(variant_column).over(partition_by=['SERIES_ID']))\n",
    "\n",
    "forecast_sdf.write.save_as_table(\"TEST_PROPHET_COMPASS\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11588f",
   "metadata": {},
   "source": [
    "## TEST Prophet==1.1.5 (Error)\n",
    "Prophet==1.1.5 is not yet supported in Snowflake Anaconda as it has some SYS calls that are blocked by Snowflake. Solution underway by Snowflake Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7dd83dc-5d93-4186-87f2-f5e720c2223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package 'lightning-utilities' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'plotly' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'pmdarima' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'pytorch' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'pytorch-lightning' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'statsmodels' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'tbats' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'torchmetrics' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'xarray' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "The version of package 'prophet' in the local environment is 1.1.5, which does not fit the criteria for the requirement 'prophet'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"TIMESTAMP\", T.DateType()),\n",
    "    T.StructField(\"FORECAST\", T.FloatType()),\n",
    "    T.StructField(\"TRAIN_START\", T.DateType()),\n",
    "    T.StructField(\"TRAIN_END\", T.DateType()),\n",
    "    T.StructField(\"FORECAST_HORIZON\", T.IntegerType()),\n",
    "    T.StructField(\"LIBRARY_VERSION\", T.StringType())\n",
    "])\n",
    "\n",
    "@F.udtf(session=session,\n",
    "        output_schema = schema,\n",
    "        input_types = [T.VariantType()],\n",
    "        name = \"TESTING_PROPHET_115_DEEN\",\n",
    "        is_permanent=True,\n",
    "        stage_location=\"@TIME_SERIES.SYNTHETIC_DATA.TEST_PROPHET_115\",\n",
    "        packages=['pandas', 'holidays', 'snowflake-snowpark-python',\n",
    "                  'importlib_resources', 'tqdm'],\n",
    "        imports = ['@TIME_SERIES.SYNTHETIC_DATA.TEST_PROPHET_115/wheel_loader.py',\n",
    "                   '@TIME_SERIES.SYNTHETIC_DATA.TEST_PROPHET_115/prophet-1.1.5.whl',\n",
    "                   '@TIME_SERIES.SYNTHETIC_DATA.TEST_PROPHET_115/cmdstanpy-1.2.0-py3-none-any.whl',\n",
    "                   '@TIME_SERIES.SYNTHETIC_DATA.TEST_PROPHET_115/stanio-0.4.0-py3-none-any.whl'],\n",
    "        replace=True\n",
    "       )\n",
    "\n",
    "class forecast:\n",
    "    def __init__(self):\n",
    "        self.rows=[]\n",
    "        self.dfs=[]\n",
    "    \n",
    "    def process(self, data):\n",
    "        self.rows.append(data)\n",
    "        # Merge rows into a dataframe\n",
    "        if len(self.rows) >= 16000:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "        # Merge dataframes into a single dataframe. Minimizes memory footprint\n",
    "        if len(self.dfs) >= 100:\n",
    "            merged_df = pd.concat(self.dfs)\n",
    "            self.dfs = [merged_df]\n",
    "        yield None\n",
    "    \n",
    "    def end_partition(self):\n",
    "        import sys, os\n",
    "        import wheel_loader\n",
    "        wheel_loader.load('prophet-1.1.5.whl')\n",
    "        wheel_loader.load('stanio-0.4.0-py3-none-any.whl')\n",
    "        wheel_loader.load('cmdstanpy-1.2.0-py3-none-any.whl')\n",
    "\n",
    "        from prophet import Prophet\n",
    "        import prophet\n",
    "\n",
    "        if len(self.rows) > 0:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "\n",
    "        # Preprocess Data\n",
    "        df_data = pd.concat(self.dfs)\n",
    "        df_data['ds'] = pd.to_datetime(df_data['DATE'])\n",
    "        df_data = df_data.groupby('ds').sum('VALUE').reset_index()\n",
    "        df_data = df_data.rename(columns={'VALUE':'y'})\n",
    "        df_data = df_data[['ds','y']]\n",
    "        df_data = df_data.sort_values(by=['ds']).reset_index(drop=True)\n",
    "\n",
    "        # Set train start\n",
    "        train_length = 600\n",
    "        forecast_horizon = 30\n",
    "        train_end = max(df_data['ds'])\n",
    "        train_start = train_end - pd.Timedelta(days = 600)\n",
    "\n",
    "        # Get training data\n",
    "        df_data = df_data.loc[(df_data['ds'] > train_start) & (df_data['ds'] <= train_end)]\n",
    "\n",
    "        # Model fit and predict\n",
    "        model = Prophet()\n",
    "        model.fit(df_data)\n",
    "        future = model.make_future_dataframe(periods=forecast_horizon)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Post process forecast\n",
    "        forecast = forecast[['ds','yhat']]\n",
    "        \n",
    "        forecast.columns = ['TIMESTAMP','FORECAST']\n",
    "        forecast['TRAIN_START'] = train_start\n",
    "        forecast['TRAIN_END'] = train_end\n",
    "        forecast['FORECAST_HORIZON'] = forecast_horizon\n",
    "        forecast['LIBRARY_VERSION'] = str(prophet.__version__)\n",
    "\n",
    "        yield from forecast.itertuples(index=False, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85f52a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
