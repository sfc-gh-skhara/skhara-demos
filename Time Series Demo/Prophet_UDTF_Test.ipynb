{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea36370",
   "metadata": {},
   "source": [
    "# Steps in this Notebook\n",
    "\n",
    "1. Imports\n",
    "2. Snowflake Setup\n",
    "3. TS Forecasting with DARTS\n",
    "4. Deployment of TS Forecasting with Snowflake Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d72538",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb04fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, StringType,StructType, StructField\n",
    "\n",
    "# import snowflake.ml.modeling.preprocessing as snowml\n",
    "# from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "# from snowflake.ml.modeling.preprocessing import KBinsDiscretizer, OrdinalEncoder, OneHotEncoder\n",
    "# from snowflake.ml.modeling.impute import SimpleImputer\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc080c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = json.load(open('/Users/skhara/Documents/Code/creds.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0697a78d-dfe2-4b7d-92a0-ae48c7053b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/skhara/Documents/GitHub/skhara-demos-public/Time Series Demo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdd95f4-7f77-4521-bf7c-e901dad9bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                    Version\n",
      "-------------------------- ----------------\n",
      "aiofiles                   22.1.0\n",
      "aiosqlite                  0.18.0\n",
      "anyio                      3.5.0\n",
      "appnope                    0.1.2\n",
      "argon2-cffi                21.3.0\n",
      "argon2-cffi-bindings       21.2.0\n",
      "asn1crypto                 1.5.1\n",
      "asttokens                  2.0.5\n",
      "attrs                      23.1.0\n",
      "Babel                      2.11.0\n",
      "backcall                   0.2.0\n",
      "beautifulsoup4             4.12.2\n",
      "bleach                     4.1.0\n",
      "Bottleneck                 1.3.5\n",
      "Brotli                     1.0.9\n",
      "cachetools                 4.2.2\n",
      "certifi                    2023.7.22\n",
      "cffi                       1.15.1\n",
      "charset-normalizer         2.0.4\n",
      "cloudpickle                2.0.0\n",
      "cmdstanpy                  1.1.0\n",
      "comm                       0.1.2\n",
      "contourpy                  1.0.5\n",
      "convertdate                2.3.2\n",
      "cryptography               41.0.3\n",
      "cycler                     0.11.0\n",
      "debugpy                    1.6.7\n",
      "decorator                  5.1.1\n",
      "defusedxml                 0.7.1\n",
      "entrypoints                0.4\n",
      "ephem                      4.1.2\n",
      "executing                  0.8.3\n",
      "fastjsonschema             2.16.2\n",
      "filelock                   3.9.0\n",
      "fonttools                  4.25.0\n",
      "holidays                   0.29\n",
      "idna                       3.4\n",
      "importlib-metadata         6.0.0\n",
      "importlib-resources        6.1.0\n",
      "ipykernel                  6.25.0\n",
      "ipython                    8.12.2\n",
      "ipython-genutils           0.2.0\n",
      "ipywidgets                 8.0.4\n",
      "jedi                       0.18.1\n",
      "Jinja2                     3.1.2\n",
      "joblib                     1.2.0\n",
      "json5                      0.9.6\n",
      "jsonschema                 4.19.2\n",
      "jsonschema-specifications  2023.7.1\n",
      "jupyter                    1.0.0\n",
      "jupyter_client             7.4.9\n",
      "jupyter-console            6.6.3\n",
      "jupyter_core               5.5.0\n",
      "jupyter-events             0.8.0\n",
      "jupyter-server             1.23.4\n",
      "jupyter_server_fileid      0.9.0\n",
      "jupyter_server_ydoc        0.8.0\n",
      "jupyter-ydoc               0.2.4\n",
      "jupyterlab                 3.6.3\n",
      "jupyterlab-pygments        0.2.2\n",
      "jupyterlab_server          2.25.1\n",
      "jupyterlab-widgets         3.0.5\n",
      "kiwisolver                 1.4.4\n",
      "LunarCalendar              0.0.9\n",
      "MarkupSafe                 2.1.1\n",
      "matplotlib                 3.7.2\n",
      "matplotlib-inline          0.1.6\n",
      "mistune                    2.0.4\n",
      "munkres                    1.1.4\n",
      "nbclassic                  1.0.0\n",
      "nbclient                   0.8.0\n",
      "nbconvert                  7.10.0\n",
      "nbformat                   5.9.2\n",
      "nest-asyncio               1.5.6\n",
      "notebook                   6.5.4\n",
      "notebook_shim              0.2.3\n",
      "numexpr                    2.8.4\n",
      "numpy                      1.24.3\n",
      "packaging                  23.1\n",
      "pandas                     2.0.3\n",
      "pandocfilters              1.5.0\n",
      "parso                      0.8.3\n",
      "pexpect                    4.8.0\n",
      "pickleshare                0.7.5\n",
      "Pillow                     10.0.1\n",
      "pip                        23.3\n",
      "pkgutil_resolve_name       1.3.10\n",
      "platformdirs               3.10.0\n",
      "ply                        3.11\n",
      "pooch                      1.7.0\n",
      "prometheus-client          0.14.1\n",
      "prompt-toolkit             3.0.36\n",
      "prophet                    1.1.4\n",
      "psutil                     5.9.0\n",
      "ptyprocess                 0.7.0\n",
      "pure-eval                  0.2.2\n",
      "pyarrow                    14.0.2\n",
      "pycparser                  2.21\n",
      "Pygments                   2.15.1\n",
      "PyJWT                      2.4.0\n",
      "PyMeeus                    0.5.11\n",
      "pyOpenSSL                  23.2.0\n",
      "pyparsing                  3.0.9\n",
      "PyQt5                      5.15.10\n",
      "PyQt5-sip                  12.13.0\n",
      "PySocks                    1.7.1\n",
      "python-dateutil            2.8.3+snowflake1\n",
      "python-json-logger         2.0.7\n",
      "pytz                       2023.3.post1\n",
      "PyYAML                     6.0.1\n",
      "pyzmq                      23.2.0\n",
      "qtconsole                  5.5.0\n",
      "QtPy                       2.4.1\n",
      "referencing                0.30.2\n",
      "requests                   2.31.0\n",
      "rfc3339-validator          0.1.4\n",
      "rfc3986-validator          0.1.1\n",
      "rpds-py                    0.10.6\n",
      "scikit-learn               1.3.0\n",
      "scipy                      1.10.1\n",
      "seaborn                    0.12.2\n",
      "Send2Trash                 1.8.2\n",
      "setuptools                 68.0.0\n",
      "sip                        6.7.12\n",
      "six                        1.16.0\n",
      "sniffio                    1.2.0\n",
      "snowflake-connector-python 3.5.0\n",
      "snowflake-snowpark-python  1.10.0\n",
      "sortedcontainers           2.4.0\n",
      "soupsieve                  2.5\n",
      "stack-data                 0.2.0\n",
      "terminado                  0.17.1\n",
      "threadpoolctl              2.2.0\n",
      "tinycss2                   1.2.1\n",
      "tomli                      2.0.1\n",
      "tomlkit                    0.11.1\n",
      "tornado                    6.3.3\n",
      "tqdm                       4.65.0\n",
      "traitlets                  5.7.1\n",
      "typing_extensions          4.7.1\n",
      "tzdata                     2023.3\n",
      "urllib3                    1.26.18\n",
      "wcwidth                    0.2.5\n",
      "webencodings               0.5.1\n",
      "websocket-client           0.58.0\n",
      "wheel                      0.41.2\n",
      "widgetsnbextension         4.0.5\n",
      "xgboost                    1.7.3\n",
      "y-py                       0.5.9\n",
      "ypy-websocket              0.8.2\n",
      "zipp                       3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb2b72d-03b5-42b3-81b4-47b081fa879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf6745",
   "metadata": {},
   "source": [
    "# Snowflake Setup: Create a Database and Schema\n",
    "\n",
    "We will be using PUBLIC schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0866765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('USE DATABASE TIME_SERIES').collect()\n",
    "session.sql('USE SCHEMA SYNTHETIC_DATA').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463a699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TS data from Store_Traffic Database into ACCRUENT_TS_FORECASTING DB for testing purposes.\n",
    "sdf_raw = session.table('TIME_SERIES_1K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6ff284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(COUNT(DISTINCT SERIES_ID)=1000)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the Number of Time Series/Pumps that we have to predict\n",
    "session.sql('SELECT COUNT(DISTINCT SERIES_ID) FROM TIME_SERIES_1K').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdff238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SUMMARY='count', SERIES_ID=2046000.0, VALUE=2046000.0),\n",
       " Row(SUMMARY='mean', SERIES_ID=500.5, VALUE=124.109512),\n",
       " Row(SUMMARY='stddev', SERIES_ID=288.67506080366553, VALUE=35.57537708865502),\n",
       " Row(SUMMARY='min', SERIES_ID=1.0, VALUE=44.0),\n",
       " Row(SUMMARY='max', SERIES_ID=1000.0, VALUE=246.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_raw.describe().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caa133",
   "metadata": {},
   "source": [
    "# Local Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41cd657a-7f5e-4ee9-b766-b1238876a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:17:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "17:17:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>FORECAST</th>\n",
       "      <th>TRAIN_START</th>\n",
       "      <th>TRAIN_END</th>\n",
       "      <th>FORECAST_HORIZON</th>\n",
       "      <th>LIBRARY_VERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>149.580651</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>136.509438</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>141.670957</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>159.879076</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>177.866228</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2023-09-03</td>\n",
       "      <td>159.915620</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>178.099985</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>196.063384</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2023-09-06</td>\n",
       "      <td>200.465051</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>2023-09-07</td>\n",
       "      <td>187.933910</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TIMESTAMP    FORECAST TRAIN_START  TRAIN_END  FORECAST_HORIZON  \\\n",
       "0   2021-12-17  149.580651  2021-12-16 2023-08-08                30   \n",
       "1   2021-12-18  136.509438  2021-12-16 2023-08-08                30   \n",
       "2   2021-12-19  141.670957  2021-12-16 2023-08-08                30   \n",
       "3   2021-12-20  159.879076  2021-12-16 2023-08-08                30   \n",
       "4   2021-12-21  177.866228  2021-12-16 2023-08-08                30   \n",
       "..         ...         ...         ...        ...               ...   \n",
       "625 2023-09-03  159.915620  2021-12-16 2023-08-08                30   \n",
       "626 2023-09-04  178.099985  2021-12-16 2023-08-08                30   \n",
       "627 2023-09-05  196.063384  2021-12-16 2023-08-08                30   \n",
       "628 2023-09-06  200.465051  2021-12-16 2023-08-08                30   \n",
       "629 2023-09-07  187.933910  2021-12-16 2023-08-08                30   \n",
       "\n",
       "    LIBRARY_VERSION  \n",
       "0             1.1.5  \n",
       "1             1.1.5  \n",
       "2             1.1.5  \n",
       "3             1.1.5  \n",
       "4             1.1.5  \n",
       "..              ...  \n",
       "625           1.1.5  \n",
       "626           1.1.5  \n",
       "627           1.1.5  \n",
       "628           1.1.5  \n",
       "629           1.1.5  \n",
       "\n",
       "[630 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = sdf_raw.filter((F.col(\"SERIES_ID\") == 62)).to_pandas()\n",
    "\n",
    "# Here onwards copy paste in UDTF\n",
    "import prophet\n",
    "\n",
    "df_data['ds'] = pd.to_datetime(df_data['DATE'])\n",
    "df_data = df_data.groupby('ds').sum('VALUE').reset_index()\n",
    "df_data = df_data.rename(columns={'VALUE':'y'})\n",
    "df_data = df_data[['ds','y']]\n",
    "df_data = df_data.sort_values(by=['ds']).reset_index(drop=True)\n",
    "\n",
    "# Set train start\n",
    "train_length = 600\n",
    "forecast_horizon = 30\n",
    "train_end = max(df_data['ds'])\n",
    "train_start = train_end - pd.Timedelta(days = 600)\n",
    "\n",
    "# Get training data\n",
    "df_data = df_data.loc[(df_data['ds'] > train_start) & (df_data['ds'] <= train_end)]\n",
    "\n",
    "# Model fit and predict\n",
    "model = prophet.Prophet()\n",
    "model.fit(df_data)\n",
    "future = model.make_future_dataframe(periods=30)\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Post process forecast\n",
    "forecast = forecast[['ds','yhat']]\n",
    "forecast.columns = ['TIMESTAMP','FORECAST']\n",
    "forecast['TRAIN_START'] = train_start\n",
    "forecast['TRAIN_END'] = train_end\n",
    "forecast['FORECAST_HORIZON'] = forecast_horizon\n",
    "forecast['LIBRARY_VERSION'] = str(prophet.__version__)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "226f5f2a-fa0b-41ca-a969-a0d7e7587f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.plot(forecast)\n",
    "# model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7dd1c",
   "metadata": {},
   "source": [
    "# Creating UDTF for multi-node parallelized model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef715fc",
   "metadata": {},
   "source": [
    "### Upload library to Snowflake Stage\n",
    "We are uploading to a stage as this library is not available through the Snowflake Anaconda Channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c8c7c1-0a77-465a-bb19-5f9a2125790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('USE DATABASE TIME_SERIES').collect()\n",
    "session.sql('USE SCHEMA SYNTHETIC_DATA').collect()\n",
    "session.sql('USE WAREHOUSE ML_WORKLOADS').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ef688-636d-4c80-87bc-7143deadaab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('CREATE STAGE IF NOT EXISTS ML_MODELS').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8cc72-bd83-496c-a082-883c03734fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import darts\n",
    "print(darts.__version__)\n",
    "print(darts.__path__[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa52f6e-fc1c-4b77-89a3-52e4356ea695",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = \"/Users/skhara/anaconda3/envs/test_snowpandas_12_18_23/lib/python3.9/site-packages/darts.zip\"\n",
    "session.file.put(zip_file_path, \"@ML_MODELS\", auto_compress=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3175af40-d703-4403-8aa7-507c36733f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.5\n",
      "/Users/skhara/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/prophet\n"
     ]
    }
   ],
   "source": [
    "import prophet\n",
    "prophet_version = prophet.__version__\n",
    "prophet_path = prophet.__path__[0]\n",
    "print(prophet_version)\n",
    "print(prophet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fdc848-c2b9-4c46-89fe-41481f4546f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = \"/Users/skhara/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/prophet.zip\"\n",
    "session.file.put(zip_file_path, \"@ML_MODELS\", auto_compress=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11588f",
   "metadata": {},
   "source": [
    "## - TEST Prophet==1.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e884cb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter custom_package_usage_config is experimental since 1.6.0. Do not use it in production. \n"
     ]
    }
   ],
   "source": [
    "session.custom_package_usage_config = {\"enabled\": True, \"cache_path\": \"@ML_MODELS\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7dd83dc-5d93-4186-87f2-f5e720c2223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'holidays' in the local environment is 0.33, which does not fit the criteria for the requirement 'holidays'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'joblib' in the local environment is 1.3.2, which does not fit the criteria for the requirement 'joblib==1.2.0'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'plotly' in the local environment is 5.17.0, which does not fit the criteria for the requirement 'plotly==5.9.0'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "Package 'pytorch' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "The version of package 'pytorch-lightning' in the local environment is 2.0.9, which does not fit the criteria for the requirement 'pytorch-lightning==2.0.3'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'torchmetrics' in the local environment is 1.1.2, which does not fit the criteria for the requirement 'torchmetrics==0.11.4'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'tqdm' in the local environment is 4.66.1, which does not fit the criteria for the requirement 'tqdm'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'xarray' in the local environment is 2023.8.0, which does not fit the criteria for the requirement 'xarray'. Your UDF might not work when the package version is different between the server and your local environment.\n"
     ]
    }
   ],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"TIMESTAMP\", T.DateType()),\n",
    "    T.StructField(\"FORECAST\", T.FloatType()),\n",
    "    T.StructField(\"TRAIN_START\", T.DateType()),\n",
    "    T.StructField(\"TRAIN_END\", T.DateType()),\n",
    "    T.StructField(\"FORECAST_HORIZON\", T.IntegerType()),\n",
    "    T.StructField(\"LIBRARY_VERSION\", T.StringType())\n",
    "])\n",
    "\n",
    "@F.udtf(output_schema = schema,\n",
    "        input_types = [T.VariantType()],\n",
    "        name = \"TESTING_PROPHET_2\",\n",
    "        is_permanent=True,\n",
    "        stage_location=\"@TIME_SERIES.SYNTHETIC_DATA.ML_MODELS\",\n",
    "        session=session,\n",
    "        packages=['pandas==1.5.3','holidays', 'snowflake-snowpark-python',\n",
    "                  'joblib==1.2.0','lightning-utilities==0.7.1','matplotlib==3.7.1',\n",
    "                  'plotly==5.9.0','pmdarima==2.0.3','pytorch==2.0.1',\n",
    "                  'pytorch-lightning==2.0.3','pyyaml==6.0','scikit-learn==1.2.2',\n",
    "                  'scipy==1.10.1','statsmodels',\n",
    "                  'tbats==1.1.3','torchmetrics==0.11.4','tqdm','xarray'],\n",
    "        imports = ['@ML_MODELS/prophet.zip'],\n",
    "        replace=True\n",
    "       )\n",
    "\n",
    "class forecast:\n",
    "    def __init__(self):\n",
    "        self.rows=[]\n",
    "        self.dfs=[]\n",
    "    \n",
    "    def process(self, data):\n",
    "        self.rows.append(data)\n",
    "\n",
    "        # Merge rows into a dataframe\n",
    "        if len(self.rows) >= 16000:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "        \n",
    "        # Merge dataframes into a single dataframe\n",
    "        # Minimizes memory footprint\n",
    "        if len(self.dfs) >= 100:\n",
    "            merged_df = pd.concat(self.dfs)\n",
    "            self.dfs = [merged_df]\n",
    "\n",
    "        yield None\n",
    "    \n",
    "    def end_partition(self):\n",
    "        from prophet import Prophet\n",
    "        import prophet\n",
    "\n",
    "        if len(self.rows) > 0:\n",
    "            df = pd.DataFrame(self.rows)\n",
    "            self.dfs.append(df)\n",
    "            self.rows = []\n",
    "\n",
    "        # Preprocess Data\n",
    "        df_data = pd.concat(self.dfs)\n",
    "        df_data['ds'] = pd.to_datetime(df_data['DATE'])\n",
    "        df_data = df_data.groupby('ds').sum('VALUE').reset_index()\n",
    "        df_data = df_data.rename(columns={'VALUE':'y'})\n",
    "        df_data = df_data[['ds','y']]\n",
    "        df_data = df_data.sort_values(by=['ds']).reset_index(drop=True)\n",
    "\n",
    "        # Set train start\n",
    "        train_length = 600\n",
    "        forecast_horizon = 30\n",
    "        train_end = max(df_data['ds'])\n",
    "        train_start = train_end - pd.Timedelta(days = 600)\n",
    "\n",
    "        # Get training data\n",
    "        df_data = df_data.loc[(df_data['ds'] > train_start) & (df_data['ds'] <= train_end)]\n",
    "\n",
    "        # Model fit and predict\n",
    "        model = Prophet()\n",
    "        model.fit(df_data)\n",
    "        future = model.make_future_dataframe(periods=forecast_horizon)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Post process forecast\n",
    "        forecast = forecast[['ds','yhat']]\n",
    "\n",
    "        # forecast = df_data.copy()\n",
    "        # forecast = forecast[['ds','y']]\n",
    "        \n",
    "        forecast.columns = ['TIMESTAMP','FORECAST']\n",
    "        forecast['TRAIN_START'] = train_start\n",
    "        forecast['TRAIN_END'] = train_end\n",
    "        forecast['FORECAST_HORIZON'] = forecast_horizon\n",
    "        forecast['LIBRARY_VERSION'] = str(prophet.__version__)\n",
    "\n",
    "        yield from forecast.itertuples(index=False, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff6c817",
   "metadata": {},
   "outputs": [
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01b16e5b-0001-f5d3-0021-d9870039b4aa: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"/var/folders/2d/stkxpskx5934bff5mzjj6l340000gn/T/ipykernel_1186/1799059119.py\", line 49, in end_partition\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 664, in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 627, in _load_backward_compatible\n  File \"<frozen zipimport>\", line 259, in load_module\n  File \"/home/udf/145383427489/prophet.zip/prophet/__init__.py\", line 12, in <module>\n    with open(here / \"__version__.py\", \"r\") as f:\nNotADirectoryError: [Errno 20] Not a directory: '/home/udf/145383427489/prophet.zip/prophet/__version__.py'\n in function TESTING_PROPHET_2 with handler compute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m variant_column \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mparse_json(df\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROW\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(T\u001b[38;5;241m.\u001b[39mVariantType()))\n\u001b[1;32m     10\u001b[0m forecast_sdf \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSERIES_ID\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     11\u001b[0m                          store_forecast_test(variant_column)\u001b[38;5;241m.\u001b[39mover(partition_by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSERIES_ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m                         )\n\u001b[0;32m---> 14\u001b[0m \u001b[43mforecast_sdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_as_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTEST_PROPHET_COMPASS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/telemetry.py:162\u001b[0m, in \u001b[0;36mdfw_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_dataframe\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 162\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     plan \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_dataframe\u001b[38;5;241m.\u001b[39m_select_statement \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_dataframe\u001b[38;5;241m.\u001b[39m_plan\n\u001b[1;32m    164\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;241m*\u001b[39mplan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    166\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrameWriter.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    167\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/dataframe_writer.py:217\u001b[0m, in \u001b[0;36mDataFrameWriter.save_as_table\u001b[0;34m(self, table_name, mode, column_order, create_temp_table, table_type, clustering_keys, statement_params, block)\u001b[0m\n\u001b[1;32m    215\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataframe\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m    216\u001b[0m snowflake_plan \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39m_analyzer\u001b[38;5;241m.\u001b[39mresolve(create_table_logic_plan)\n\u001b[0;32m--> 217\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnowflake_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AsyncResultType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNO_RESULT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:452\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    443\u001b[0m     is_in_stored_procedure()\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m ):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync query is not supported in stored procedure yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m     )\n\u001b[0;32m--> 452\u001b[0m result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:187\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    185\u001b[0m         e\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:116\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    118\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:553\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    552\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 553\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_job_plan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcase_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    567\u001b[0m     result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mquery_id\n\u001b[1;32m    568\u001b[0m )\n\u001b[1;32m    569\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mdescription\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:103\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    100\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:97\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    100\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    101\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:367\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m         query_id_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/snowpark/_internal/server_connection.py:348\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 348\u001b[0m     results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    350\u001b[0m         QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    351\u001b[0m     )\n\u001b[1;32m    352\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/connector/cursor.py:908\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m    904\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    905\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m    907\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m--> 908\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/connector/errors.py:290\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    269\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    298\u001b[0m             error_class,\n\u001b[1;32m    299\u001b[0m             error_value,\n\u001b[1;32m    300\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/connector/errors.py:345\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pysnowpark_ml_09_2023/lib/python3.9/site-packages/snowflake/connector/errors.py:221\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    219\u001b[0m errno \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m done_format_msg \u001b[38;5;241m=\u001b[39m error_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    222\u001b[0m     msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    223\u001b[0m     errno\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(errno),\n\u001b[1;32m    224\u001b[0m     sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    225\u001b[0m     sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    226\u001b[0m     query\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    227\u001b[0m     done_format_msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m done_format_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(done_format_msg)\n\u001b[1;32m    229\u001b[0m     ),\n\u001b[1;32m    230\u001b[0m     connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    231\u001b[0m     cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    232\u001b[0m )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 01b16e5b-0001-f5d3-0021-d9870039b4aa: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"/var/folders/2d/stkxpskx5934bff5mzjj6l340000gn/T/ipykernel_1186/1799059119.py\", line 49, in end_partition\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 664, in _load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 627, in _load_backward_compatible\n  File \"<frozen zipimport>\", line 259, in load_module\n  File \"/home/udf/145383427489/prophet.zip/prophet/__init__.py\", line 12, in <module>\n    with open(here / \"__version__.py\", \"r\") as f:\nNotADirectoryError: [Errno 20] Not a directory: '/home/udf/145383427489/prophet.zip/prophet/__version__.py'\n in function TESTING_PROPHET_2 with handler compute"
     ]
    }
   ],
   "source": [
    "df = session.table('TIME_SERIES_1K') \\\n",
    "        .with_column('ROW', F.object_construct_keep_null('*')) \\\n",
    "        .select(F.col('SERIES_ID'), F.col('ROW')) \\\n",
    "        .filter(F.col('SERIES_ID').isin([1,2,3,4,5]))\n",
    "\n",
    "store_forecast_test = F.table_function(\"TESTING_PROPHET_2\")\n",
    "\n",
    "variant_column = F.parse_json(df.col('ROW').cast(T.VariantType()))\n",
    "\n",
    "forecast_sdf = df.select(F.col('SERIES_ID'),\n",
    "                         store_forecast_test(variant_column).over(partition_by=['SERIES_ID'])\n",
    "                        )\n",
    "\n",
    "forecast_sdf.write.save_as_table(\"TEST_PROPHET_COMPASS\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8d1d6-6db4-4f63-a252-63d73157f356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>FORECAST</th>\n",
       "      <th>TRAIN_START</th>\n",
       "      <th>TRAIN_END</th>\n",
       "      <th>FORECAST_HORIZON</th>\n",
       "      <th>LIBRARY_VERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>129.575846</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>118.280887</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>122.753493</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>138.516870</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>154.082572</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>157.777474</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-23</td>\n",
       "      <td>161.631877</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>150.820981</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>133.532939</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>122.219051</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SERIES_ID   TIMESTAMP    FORECAST TRAIN_START   TRAIN_END  \\\n",
       "0           3  2021-12-17  129.575846  2021-12-16  2023-08-08   \n",
       "1           3  2021-12-18  118.280887  2021-12-16  2023-08-08   \n",
       "2           3  2021-12-19  122.753493  2021-12-16  2023-08-08   \n",
       "3           3  2021-12-20  138.516870  2021-12-16  2023-08-08   \n",
       "4           3  2021-12-21  154.082572  2021-12-16  2023-08-08   \n",
       "..        ...         ...         ...         ...         ...   \n",
       "95          3  2022-03-22  157.777474  2021-12-16  2023-08-08   \n",
       "96          3  2022-03-23  161.631877  2021-12-16  2023-08-08   \n",
       "97          3  2022-03-24  150.820981  2021-12-16  2023-08-08   \n",
       "98          3  2022-03-25  133.532939  2021-12-16  2023-08-08   \n",
       "99          3  2022-03-26  122.219051  2021-12-16  2023-08-08   \n",
       "\n",
       "    FORECAST_HORIZON LIBRARY_VERSION  \n",
       "0                 30             1.0  \n",
       "1                 30             1.0  \n",
       "2                 30             1.0  \n",
       "3                 30             1.0  \n",
       "4                 30             1.0  \n",
       "..               ...             ...  \n",
       "95                30             1.0  \n",
       "96                30             1.0  \n",
       "97                30             1.0  \n",
       "98                30             1.0  \n",
       "99                30             1.0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_sdf = session.table('TEST_PROPHET_COMPASS')\n",
    "temp_sdf.limit(100).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b2e82-df48-408c-aaa4-fa8a8e1f53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5aace-ad30-49be-a877-f50caf0f76ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
